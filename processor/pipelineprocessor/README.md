# Pipeline Processor

<!-- status autogenerated section -->
| Status        |           |
| ------------- |-----------|
| Stability     | [beta]: traces, metrics, logs   |
| Distributions | [core], [contrib], [k8s] |
| Issues        | [![Open issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector?query=is%3Aissue%20is%3Aopen%20label%3Aprocessor%2Fpipeline%20&label=open&color=orange&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector/issues?q=is%3Aopen+is%3Aissue+label%3Aprocessor%2Fpipeline) [![Closed issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector?query=is%3Aissue%20is%3Aclosed%20label%3Aprocessor%2Fpipeline%20&label=closed&color=blue&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector/issues?q=is%3Aclosed+is%3Aissue+label%3Aprocessor%2Fpipeline) |

[beta]: https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/component-stability.md#beta
[core]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol
[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib
[k8s]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-k8s
<!-- end autogenerated section -->

The pipeline processor provides advanced pipeline management capabilities including queuing, batching, retry logic, and timeout handling within OpenTelemetry Collector pipelines. It leverages the same robust infrastructure as exporters through the exporterhelper package.

Unlike the basic batch processor, the pipeline processor offers:
- **Advanced queuing** with configurable backpressure handling
- **Intelligent batching** with min/max size controls and flush timeouts
- **Exponential backoff retry** logic for handling transient failures
- **Configurable timeouts** for individual operations
- **Persistent queue support** via storage extensions

The pipeline processor should be positioned in the pipeline where you need these capabilities before data reaches exporters.

Please refer to [config.go](./config.go) for the config spec.

## Configuration

The pipeline processor uses the exact same configuration structure as the OTLP exporter for consistency:

### Basic Configuration

```yaml
processors:
  pipeline:
    # Timeout for individual operations (required)
    timeout: 5s
```

### Queue Configuration

```yaml
processors:
  pipeline:
    timeout: 5s
    sending_queue:
      enabled: true
      num_consumers: 10
      queue_size: 1000
      block_on_overflow: false
      
      # Optional batching within the queue  
      batch:
        flush_timeout: 1s
        min_size: 100
        max_size: 1000
```

### Retry Configuration

```yaml
processors:
  pipeline:
    timeout: 5s
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 5m
      multiplier: 1.5
```

### Complete Configuration

```yaml
processors:
  pipeline:
    # Timeout configuration (required)
    timeout: 10s
    
    # Queue configuration with batching
    sending_queue:
      enabled: true
      num_consumers: 10
      queue_size: 5000
      block_on_overflow: true
      
      batch:
        flush_timeout: 2s
        min_size: 512
        max_size: 2048
    
    # Retry configuration  
    retry_on_failure:
      enabled: true
      initial_interval: 1s
      max_interval: 30s
      max_elapsed_time: 300s
      multiplier: 2.0
```

### Persistent Queue

To enable persistent queuing with storage:

```yaml
extensions:
  file_storage:
    directory: /var/lib/otelcol-storage

processors:
  pipeline:
    timeout: 5s
    sending_queue:
      enabled: true
      storage: file_storage
      queue_size: 1000

service:
  extensions: [file_storage]
  pipelines:
    traces:
      receivers: [otlp]
      processors: [pipeline]
      exporters: [otlp]
```

## Configuration Options

### Timeout Settings

- `timeout` (default = 5s): Timeout for individual operations. Unlike queue/retry/batch settings, timeout is always enabled.

### Queue Settings (`sending_queue`)

- `enabled` (default = false): Enable/disable queuing
- `num_consumers` (default = 10): Number of concurrent consumers
- `queue_size` (default = 1000): Maximum queue size  
- `block_on_overflow` (default = false): Block when queue is full vs drop data
- `storage` (optional): Storage extension for persistent queuing

### Batch Settings (`sending_queue.batch`)

- `flush_timeout` (required if batch enabled): Maximum time to wait before sending batch
- `min_size` (default = 0): Minimum batch size
- `max_size` (default = 0): Maximum batch size

### Retry Settings (`retry_on_failure`)

- `enabled` (default = false): Enable/disable retry logic
- `initial_interval` (default = 5s): Initial retry delay
- `max_interval` (default = 30s): Maximum retry delay  
- `max_elapsed_time` (default = 5m): Total time to keep retrying
- `multiplier` (default = 1.5): Backoff multiplier

## Use Cases

### High-Throughput Pipelines

For high-volume data processing with backpressure management:

```yaml
processors:
  pipeline:
    timeout: 30s
    sending_queue:
      enabled: true
      num_consumers: 20
      queue_size: 10000
      batch:
        flush_timeout: 5s
        min_size: 1000
        max_size: 5000
```

### Reliable Data Processing

For critical data that requires retry and persistence:

```yaml
processors:
  pipeline:
    timeout: 10s
    sending_queue:
      enabled: true
      storage: file_storage
      queue_size: 5000
    retry_on_failure:
      enabled: true
      max_elapsed_time: 10m
```

### Migration from Batch Processor

Replace `batch` processor with equivalent functionality:

```yaml
# Old batch processor config
processors:
  batch:
    send_batch_size: 1024
    timeout: 1s

# New pipeline processor equivalent  
processors:
  pipeline:
    timeout: 30s  # Per-operation timeout
    sending_queue:
      enabled: true
      batch:
        flush_timeout: 1s
        min_size: 1024
```

## Observability

The pipeline processor provides metrics for monitoring queue depth, batch sizes, retry attempts, and timeout occurrences. These metrics help with performance tuning and operational monitoring.

Refer to [testdata/config.yaml](./testdata/config.yaml) for additional configuration examples.
