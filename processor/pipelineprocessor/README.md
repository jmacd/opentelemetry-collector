# Pipeline Processor

<!-- status autogenerated section -->
| Status        |           |
| ------------- |-----------|
| Stability     | [development]: traces, metrics, logs   |
|               | [alpha]: profiles   |
| Distributions | [] |
| Issues        | [![Open issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector?query=is%3Aissue%20is%3Aopen%20label%3Aprocessor%2Fpipeline%20&label=open&color=orange&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector/issues?q=is%3Aopen+is%3Aissue+label%3Aprocessor%2Fpipeline) [![Closed issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector?query=is%3Aissue%20is%3Aclosed%20label%3Aprocessor%2Fpipeline%20&label=closed&color=blue&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector/issues?q=is%3Aclosed+is%3Aissue+label%3Aprocessor%2Fpipeline) |
| Code coverage | [![codecov](https://codecov.io/github/open-telemetry/opentelemetry-collector/graph/main/badge.svg?component=processor_pipeline)](https://app.codecov.io/gh/open-telemetry/opentelemetry-collector/tree/main/?components%5B0%5D=processor_pipeline&displayType=list) |

[development]: https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/component-stability.md#development
[alpha]: https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/component-stability.md#alpha
<!-- end autogenerated section -->

## Overview

The pipeline processor provides general-purpose functions that are
typically exporter built-ins, for non-exporter components. This
component is provided as a catch-all for managing **backpressure**,
**error propagation**, **queueing**, **timeout** and **retry** within
OpenTelemetry Collector pipelines in scenarios where a processor is
necessary, as opposed to an exporter.

See [exporterhelper](../../exporter/exporterhelper/README.md) to learn
about these features in more detail..

**By default, the pipeline processor is a pass-through component**
with all functions disabled.  Features can be individually enabled via
configuration.

## Rationale

The functionality exposed by this component belongs to
"exporterhelper" and is available for all exporters because the
combination of queuing, batching, retrying, and exporting in a
specific format can be optimized to avoid repeated serialization and
deserialization.  While this is a useful (and optimizable) location
for managing these features, there are still times when a component
other than an exporter (e.g., a processor or connector) can benefit
from:

- larger or smaller batch sizes
- persistent queue ahead of high-latency processor
- in-memory queue to suppress errors.

The pipeline processor makes these capabilities available earlier in
the pipeline.

## Configuration Overview

The pipeline processor provides three independent feature sets, each disabled by default:

1. **[Timeout Configuration](#timeout-configuration)** - Deadline enforcement (disabled: deadline passes through)
2. **[Sending Queue Configuration](#sending-queue-configuration)** - Backpressure and batching (disabled: no queue, direct pass-through)
3. **[Retry Configuration](#retry-configuration)** - Error handling and recovery (disabled: no retries)

Users can enable any combination of these features based on their specific requirements.

## Timeout Configuration

Controls deadline enforcement for data processing operations.

**Default**: Disabled (no timeout enforced)

```yaml
processors:
  pipeline:
    # Limit timeout to no more than 30s
    timeout: 30s
```

When enabled, operations that exceed the timeout will be
cancelled. This does not immediately return control to the caller, it
just signals the context is canceled and allows control to return.

## Sending Queue Configuration

Provides backpressure management and optional batching capabilities.

**Default**: Disabled (no queue, direct pass-through)

### Basic Queue

```yaml
processors:
  pipeline:
    sending_queue:
      enabled: true
      num_consumers: 10
      queue_size: 1000
```

### Queue with Batching

```yaml
processors:
  pipeline:
    sending_queue:
      enabled: true
      num_consumers: 10
      queue_size: 1000
      sizer: requests
      batch:
        flush_timeout: 1s
        min_size: 100
        max_size: 1000
```

### Persistent Queue

```yaml
extensions:
  file_storage:
    directory: /var/lib/otelcol-storage

processors:
  pipeline:
    sending_queue:
      enabled: true
      storage: file_storage  # Enables persistence
      queue_size: 1000
```

For complete configuration options, see the [exporterhelper queue documentation](../../exporter/exporterhelper/README.md#queuing).

## Retry Configuration

Handles transient failures with exponential backoff retry logic.

**Default**: Disabled (no retries, immediate failure propagation)

```yaml
processors:
  pipeline:
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 5m
      multiplier: 1.5
```

For complete configuration options, see the [exporterhelper retry documentation](../../exporter/exporterhelper/README.md#retry).

## Use Cases and Examples

### Migrating from Batch Processor

Replace the legacy batch processor with equivalent functionality:

```yaml
# Legacy batch processor configuration
processors:
  batch:
    send_batch_size: 1000
    timeout: 1s

# Pipeline processor equivalent
processors:
  pipeline:
    sending_queue:
      enabled: true
      sizer: items              # Match batch processor's item-based batching
      batch:
        flush_timeout: 1s       # Equivalent to batch timeout
        min_size: 1000          # Equivalent to send_batch_size
```

### Error Propagation with Wait for Response

Enable error propagation when you need immediate feedback from downstream components:

```yaml
processors:
  pipeline:
    sending_queue:
      enabled: true
      wait_for_result: true     # Propagate errors back to sender
      block_on_overflow: true
      queue_size: 1000
```
